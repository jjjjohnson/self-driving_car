{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "from Line import Line\n",
    "from utility import *\n",
    "from calibrate_utility import calibrate_cramera, undistort\n",
    "from binary_threshold import combined_threshold\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import cv2\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mtx, dist = calibrate_cramera()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bad_count = 99 # Initialize the bad count in order to start with sliding window search\n",
    "def process_image(image):\n",
    "    \"\"\"Takes as input a color imge. Then:\n",
    "    1. Undistort the image.\n",
    "    2. Combined edge detection.\n",
    "    3. Transfer to bird eye.\n",
    "    *4. line detection, smooth. sanity check\"\"\"\n",
    "    global bad_count\n",
    "    h,w,c = image.shape\n",
    "    undistorted_img = undistort(image, mtx, dist)\n",
    "    threshold_img = combined_threshold(undistorted_img)\n",
    "    birdeye_img = warp(threshold_img)\n",
    "    if bad_count > 5 or rline.detected or lline.detected:\n",
    "        bad_count = 0\n",
    "        sliding_window_search(birdeye_img,h,rline,lline) # 2D image\n",
    "    else:\n",
    "        previous_fit_window_search(birdeye_img,rline,lline)\n",
    "    # Check the distance between the two lines\n",
    "    if (rline.poly_fit_meter[2]-lline.poly_fit_meter[2]) > 5 or (rline.poly_fit_meter[2]-lline.poly_fit_meter[2]) < 4:\n",
    "        bad_count += 1 # log the times bad frame encountered\n",
    "        left_length = len(lline.recent_fits)\n",
    "        right_length = len(rline.recent_fits)\n",
    "        lline.recent_fits = deque(itertools.islice(lline.recent_fits,0,left_length-1), maxlen=15)\n",
    "        rline.recent_fits = deque(itertools.islice(rline.recent_fits,0,right_length-1), maxlen=15)\n",
    "        lline.recent_fits_meter = deque(itertools.islice(lline.recent_fits_meter,0,left_length-1), maxlen=15)\n",
    "        rline.recent_fits_meter = deque(itertools.islice(rline.recent_fits_meter,0,right_length-1), maxlen=15)\n",
    "    output = draw_back(birdeye_img, rline, lline)\n",
    "    #Add text to image\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    offset = calculate_offset(h,w,rline,lline)\n",
    "    if offset >= 0:\n",
    "        cv2.putText(output, 'Vehicle is {:.2f} (m) to the right'.format(offset), (800, 60), font, 0.9, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    else:\n",
    "        cv2.putText(output, 'Vehicle is {:.2f} (m) to the left'.format(-offset), (800, 60), font, 0.9, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    curvature = (lline.curvature_meter+rline.curvature_meter) / 2\n",
    "    if curvature < 5000:\n",
    "        cv2.putText(output, 'Radius of Curvature {:.2f}m '.format(curvature), (800, 100), font, 0.9, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    else:\n",
    "        cv2.putText(output, 'Road is straight ', (800, 100), font, 0.9, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    combo = cv2.addWeighted(image, 1, output, 1, 0.)\n",
    "    \n",
    "    return combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_video_output.mp4\n",
      "[MoviePy] Writing video project_video_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [06:10<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video_output.mp4 \n",
      "\n",
      "CPU times: user 9min 22s, sys: 1min 6s, total: 10min 29s\n",
      "Wall time: 6min 11s\n"
     ]
    }
   ],
   "source": [
    "rline = Line()\n",
    "lline = Line()\n",
    "white_output = 'project_video_output.mp4'\n",
    "clip1 = VideoFileClip(\"../project_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"project_video_output.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:IntroToTensorFlow]",
   "language": "python",
   "name": "conda-env-IntroToTensorFlow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
